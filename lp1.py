# -*- coding: utf-8 -*-
"""LP1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VKID61rmWehrEY65RZ2gWR2RfTd3kEL_
"""

import pandas as pd
import numpy as np
import os

train = pd.read_csv('/content/train_u6lujuX_CVtuZ9i.csv')
train.Loan_Status = train.Loan_Status.map({'Y':1,'N':0})

train.head()

train.describe()

train.isnull().sum()

Loan_Status = train.Loan_Status
train.drop('Loan_Status',axis=1,inplace=True)
test = pd.read_csv('/content/test_Y3wMUE5_7gLdaTN.csv')
Loan_ID = test.Loan_ID
data = train.append(test)
data.head()

data.shape

data.describe

data.isnull().sum()

data.Dependents.dtypes

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline
corrmat = data.corr()
f,ax = plt.subplots(figsize=(9,9))
sns.heatmap(corrmat, vmax=.8, square=True)

data.Gender = data.Gender.map({'Male':1,'Female':0})
data.Gender.value_counts()

corrmat = data.corr()
f,ax = plt.subplots(figsize=(9,9))
sns.heatmap(corrmat, vmax=.8, square=True)

data.Married = data.Married.map({'Yes':1,'No':0})
data.Married.value_counts()

data.Dependents = data.Dependents.map({'0':0,'1':1,'2':2,'3+':3})
data.Dependents.value_counts()

corrmat = data.corr()
f,ax = plt.subplots(figsize=(9,9))
sns.heatmap(corrmat, vmax=.8, square=True)

data.Education = data.Education.map({'Graduate':1,'Not Graduate':0})
data.Education.value_counts()

data.Self_Employed = data.Self_Employed.map({'Yes':1,'No':0})
data.Self_Employed.value_counts()

data.Property_Area = data.Property_Area.map({'Rural':0,'Semiurban':1,'Urban':2})
data.Property_Area.value_counts()

corrmat = data.corr()
f,ax = plt.subplots(figsize=(9,9))
sns.heatmap(corrmat, vmax=.8, square=True)

data.head()

data.Credit_History.fillna(np.random.randint(0,2),inplace=True)
data.isnull().sum()

data.Married.fillna(np.random.randint(0,2),inplace=True)
data.isnull().sum()

data.LoanAmount.fillna(data.LoanAmount.median(),inplace=True)
data.isnull().sum()

data.LoanAmount.fillna(data.LoanAmount.mean(),inplace=True)
data.isnull().sum()

data.Gender.fillna(np.random.randint(0,2),inplace=True)
data.isnull().sum()

data.Dependents.fillna(data.Dependents.median(),inplace=True)
data.isnull().sum()

data.Self_Employed.fillna(np.random.randint(0,2),inplace=True)
data.isnull().sum()

data.Loan_Amount_Term.fillna(data.Loan_Amount_Term.median(),inplace=True)
data.isnull().sum()

data.drop('Loan_ID',inplace=True,axis=1)

train_x = data.iloc[:614,] #all the data in x(train set)
train_y = Loan_Status  #loan status will be our y

from sklearn.model_selection import train_test_split
train_x,test_x,train_y,test_y = train_test_split(train_x,train_y,random_state=0)

train_x.head()

test_x.head()

from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

models=[]
models.append(("Logistic Regression",LogisticRegression()))
models.append(("Decision Tree",DecisionTreeClassifier()))
models.append(("Linear Discriminant Analysis",LinearDiscriminantAnalysis()))
models.append(("Random Forest",RandomForestClassifier()))
models.append(("Support Vector Classifier",SVC()))
models.append(("K- Neirest Neighbour",KNeighborsClassifier()))
models.append(("Naive Bayes",GaussianNB()))

scoring='accuracy'

from sklearn.model_selection import KFold 
from sklearn.model_selection import cross_val_score
result=[]
names=[]

for name,model in models:
    kfold=KFold(n_splits=10,random_state=0, shuffle = True)
    cv_result=cross_val_score(model,train_x,train_y,cv=kfold,scoring=scoring)
    result.append(cv_result)
    names.append(name)
    print(model)
    print("%s %f" % (name,cv_result.mean()))

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

LR=LogisticRegression()
LR.fit(train_x,train_y)
pred=LR.predict(test_x)
print("Model Accuracy:- ",accuracy_score(test_y,pred))
print(confusion_matrix(test_y,pred))
print(classification_report(test_y,pred))

print(pred)

x_test=data.iloc[614:,]

x_test.head()

prediction = LR.predict(x_test)

print(prediction)

t = LR.predict([[0.0,	0.0,	0.0,	1,	0.0,	1811,	1666.0,	54.0,	360.0,	1.0,	2]])

print(t)

